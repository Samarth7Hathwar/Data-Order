{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0749fd-8ed8-449a-8ad7-96c2cec33e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from timm import create_model\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# dataset path\n",
    "data_path = '/Volumes/WD Harddisk/Desktop/Masterss/3rd Sem (WS 24-25)/Project/Dataset/tiny-imagenet-200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfcf57d-66ba-4bab-b110-1b8bc5a1e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transformations\n",
    "transform = transforms.Compose([\n",
    "    # Resize to 64x64 pixels\n",
    "    transforms.Resize((64, 64)), \n",
    "    # Convert images to PyTorch tensors\n",
    "    transforms.ToTensor(),  \n",
    "    # Normalize for ImageNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dir = f\"{data_path}/train\"\n",
    "val_dir = f\"{data_path}/val\"\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "\n",
    "# Reducing dataset to 50 classes \n",
    "num_classes = 50\n",
    "selected_classes = sorted(train_data.classes)[:num_classes]  # Select the first 50 classes\n",
    "\n",
    "def filter_dataset(dataset, allowed_classes):\n",
    "    indices = [i for i, (_, label) in enumerate(dataset) if dataset.classes[label] in allowed_classes]\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# Filtering datasets to include only selected classes\n",
    "train_data = filter_dataset(train_data, selected_classes)\n",
    "val_data = filter_dataset(val_data, selected_classes)\n",
    "\n",
    "print(f\"Dataset filtered to {num_classes} classes.\")\n",
    "print(f\"Training data size: {len(train_data)}, Validation data size: {len(val_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c623032-f0b0-4687-8090-9b8847ff7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(classes_subset, dataset, batch_size=32):\n",
    "    #     Generate DataLoader for specific class subsets.\n",
    "    indices = [i for i, (_, label) in enumerate(dataset) if label in classes_subset]\n",
    "    subset = Subset(dataset, indices)\n",
    "    return DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3019359-b47f-40b7-bf4a-ec28fe78740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFNetWrapper(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NFNetWrapper, self).__init__()\n",
    "        # Loading NFNet with specified number of output classes\n",
    "        self.model = create_model('nfnet_f0', pretrained=False, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c23b3-2961-4115-b05e-6d000c03d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabetical and random orders\n",
    "alphabetical_order = list(range(num_classes))\n",
    "random_order = np.random.permutation(num_classes).tolist()\n",
    "\n",
    "# Generate dissimilar order using clustering\n",
    "def get_dissimilar_order(dataset):\n",
    "    from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "    # Feature extraction\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    resnet = nn.Sequential(*list(resnet.children())[:-1])  # Remove the classification layer\n",
    "    resnet.eval()\n",
    "    resnet.to(device)\n",
    "\n",
    "    # Extract features for each class\n",
    "    features = []\n",
    "    for class_idx in range(num_classes):\n",
    "        loader = get_loader([class_idx], dataset, batch_size=16)\n",
    "        class_features = []\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            with torch.no_grad():\n",
    "                output = resnet(images).view(images.size(0), -1)\n",
    "                class_features.append(output.mean(dim=0).cpu().numpy())\n",
    "        features.append(np.mean(class_features, axis=0))\n",
    "\n",
    "    # Perform clustering\n",
    "    kmeans = KMeans(n_clusters=10, random_state=42).fit(features)\n",
    "    return sorted(range(num_classes), key=lambda i: kmeans.labels_[i])\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(\"Generating dissimilar order...\")\n",
    "dissimilar_order = get_dissimilar_order(train_data)\n",
    "\n",
    "print(\"Class orders created: Alphabetical, Random, and Dissimilar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00341050-89d3-4574-b5a6-adccaaaf8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_incrementally(net, train_data, val_loader, order, num_epochs=3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "    all_acc = []\n",
    "\n",
    "    for step in range(2, num_classes + 2, 10):  # Add classes in steps of 10\n",
    "        current_classes = order[:step]\n",
    "        current_class_names = [selected_classes[i] for i in current_classes]\n",
    "        print(f\"Training with classes: {current_class_names}\")\n",
    "\n",
    "        train_loader = get_loader(current_classes, train_data)\n",
    "\n",
    "        # Training loop\n",
    "        net.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Validation after each step\n",
    "        acc = validate(net, val_loader)\n",
    "        all_acc.append(acc)\n",
    "        print(f\"Accuracy after training on {len(current_classes)} classes: {acc:.2f}%\")\n",
    "    return all_acc\n",
    "\n",
    "def validate(net, loader):\n",
    "    net.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ff130-bf03-4b03-b9c8-7b32499fe92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining with Alphabetical Order\")\n",
    "net = NFNetWrapper(num_classes=num_classes).to(device)\n",
    "acc_alphabetical = train_incrementally(net, train_data, val_loader, alphabetical_order)\n",
    "\n",
    "print(\"\\nTraining with Random Order\")\n",
    "net = NFNetWrapper(num_classes=num_classes).to(device)\n",
    "acc_random = train_incrementally(net, train_data, val_loader, random_order)\n",
    "\n",
    "print(\"\\nTraining with Dissimilar Order\")\n",
    "net = NFNetWrapper(num_classes=num_classes).to(device)\n",
    "acc_dissimilar = train_incrementally(net, train_data, val_loader, dissimilar_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da6337-a904-4c0d-a58d-1867ca5fe00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, num_classes + 2, 10), acc_alphabetical, label='Alphabetical Order', marker='o')\n",
    "plt.plot(range(2, num_classes + 2, 10), acc_random, label='Random Order', marker='o')\n",
    "plt.plot(range(2, num_classes + 2, 10), acc_dissimilar, label='Dissimilar Order', marker='o')\n",
    "\n",
    "plt.xlabel('Number of Classes')\n",
    "plt.ylabel('Validation Accuracy (%)')\n",
    "plt.title('Validation Accuracy vs Number of Classes')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
